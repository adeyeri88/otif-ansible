---
# tasks file for config_wsm_crawler_vm

- name: Make sure Kafka/Zookeeper, MongoDB, PostgreSQL and Pipeline  services ar running
  systemd:
    state: started
    daemon_reload: yes
    enabled: yes
    name: "{{ item.name }}"
  with_items:
    - { name: kafka }
    - { name: ot-zk-1 }
    - { name: mongod }
    - { name: postgresql-9.4 }
    - { name: otif-wsm-crawler-1 }
    - { name: infofusion-web-crawling-1 }
    

- name: Wait for Kafka & Zk services on ports 9092/2181. PostgreSQL on 5432. WSM Crawler services on port 10010/11. MongoDB on 27017
  wait_for:
    host: "127.0.0.1"
    port: "{{ item.port }}"
    state: started
  with_items:
#    - { port: 9092 }
    - { port: 2181 }    
    - { port: 27017 }
    - { port: 5432 }
    - { port: 10010 }
    - { port: 10011 }
    

- name: Install kazoo & pymongo dependency - needed for the Ansible znode module used to talk to Zookeeper
  become: true
  easy_install:
    name: "{{ item }}"
    state: latest
  with_items:
    - kazoo
    - pymongo

- name: Remove znode reserved for Discovery Service (wrong place if it's there!)
  znode:
    hosts: 'localhost:2181'
    name: '/ot'
    recursive: yes
    state: absent

- name: Set authentication for admin user
  mongodb_user:
    database: admin
    name: "admin"
    password: "admin"
    update_password: on_create
    roles: root 
    state: present

- name: Create magellan db in MongoDB and set authentication for users admin & magellan
  mongodb_user:
    login_user: admin
    login_password: admin
    database: magellan
    name: "{{ item.name }}"
    password: "{{ item.pwd }}"
    update_password: on_create
    roles: "{{ item.roles }}"
    state: present
  with_items:
    - { name: "magellan", pwd: "magellan", roles: "dbOwner,userAdmin" }
    - { name: "admin", pwd: "admin", roles: "userAdmin" }


- name: Authenticate to the Admin UI to get cookie
  uri:
    url: "http://{{ wsm_crawler_fqdn }}:10010/crawlers-admin/rest/v1/authentication/login"
    method: POST
    body: "username=admin&password=admin"
    status_code: 200
    headers:
      Content-Type: "application/x-www-form-urlencoded"
  register: login

- name: Create a sample Twitter Access Token
  uri:
    url: "http://{{ wsm_crawler_fqdn }}:10010/crawlers-admin/rest/v1/crawlertypes/Twitter/configs"
    method: POST
    body: {"config_id":"test","props":[{"prop_name":"CONSUMER_KEY","prop_value":"jCF3SP0aFiqkDwvw5UO52pzEm"},{"prop_name":"CONSUMER_SECRET","prop_value":"9CJYOOBR9mSBL0gC1alejvyvfICXFiFMts66NKIk3vInQLj3FZ"},{"prop_name":"ACCESS_TOKEN","prop_value":"12842652-i1qoXufhBX7ZHyrq6xyA32Z3SGVTvRBRFzyNlWSmz"},{"prop_name":"ACCESS_SECRET","prop_value":"COlIFpmBWjaHs66HhkwwIUTFCUkiDCoyfyWaOGtUT5oSb"}]}
    status_code: 201, 400
    body_format: json
    timeout: 10
    headers:
      Cookie: "{{login.set_cookie}}"
  register: request_otif

- name: 
  debug:
    var: request_otif

- name: Create a sample Twitter crawling job
  uri: 
    url: "http://{{ wsm_crawler_fqdn }}:10010/crawlers-admin/rest/v1/jobs"
    method: POST
    body: {"schedule_info":{"repeat_count":0,"recurrence":0},"search_text":{"criteria":{"type":"twitter_search","words":{"include_all_these":[],"include_any_of_these":[],"not_include_these":[],"include_these_hashtags":["#opentext"],"exact_phrase":null},"dates":null,"language":null,"surrounding_to":null,"people":null,"others":{"positive":false,"negative":false,"question":false,"include_retweets":false,"result_type":"mixed"}}},"job_id":1,"name":"Sample Twitter Crawling Job","status":"Unscheduled","description":"This is a sample Twitter crawling job","crawler_subtype":"Twitter Search","job_group":"OpenText","exec_info":{"id":0,"job_id":1}}
    status_code: 201, 400
    body_format: json
    timeout: 10
    headers:
      Cookie: "{{login.set_cookie}}"
  register: request_otif

- name:
  debug:
    var: request_otif

- name: Create a sample Web crawling job
  uri: 
    url: "http://{{ wsm_crawler_fqdn }}:10010/crawlers-admin/rest/v1/jobs"
    method: POST
    body: {"schedule_info":{"repeat_count":0,"recurrence":0},"search_text":{"numberOfCycles":5,"batchSize":50,"configuration":{},"urls":["http://www.nasdaq.com/symbol/otex/news-headlines"],"url_filters":[{"expression":".*/amp$","type":"EXCLUDE"},{"expression":"http://www.nasdaq.com/symbol/otex/news-headlines*","type":"INCLUDE"},{"expression":"http://www.nasdaq.com/article/*","type":"INCLUDE"}],"scrapingRules":[{"targetField":"document.metadata.attributes.creationDate","textExtraction":{"concatenate":false,"xpaths":["//meta[@property=\"article:published_time\"]/@content"]},"textTransformation":[{"type":"dateFormatting","parameters":{"format":"yyyy-MM-dd'T'HH:mm:ssZ"}}]},{"targetField":"document.metadata.extensions.crawler.web_content_source","textExtraction":{"concatenate":false,"xpaths":["//*[@property=\"og:site_name\"]/@content"]},"textTransformation":[{"type":"regexSubstitution","parameters":{"regex":"(.*)","replacement":"$1"}}]}]},"job_id":2,"name":"Sample Web Crawling Job","status":"Unscheduled","description":"This is a sample Web crawling job","crawler_subtype":"Nutch","job_group":"OpenText","exec_info":{"id":0,"job_id":2}}
    status_code: 201, 400
    body_format: json
    timeout: 10
    headers:
      Cookie: "{{login.set_cookie}}"
  register: request_otif

- name:
  debug:
    var: request_otif

- name:
  vars:
    msg: |
         Magellan Crawler for Web & Social Media has been configured on {{ansible_host}}.
         Two sample crawling jobs have bee created to test with.
         You can validate deployement by opening http://{{ansible_host}}:10010
         Default credentials are admin/admin.
  debug:
    msg: "{{ msg.split('\n') }}"
